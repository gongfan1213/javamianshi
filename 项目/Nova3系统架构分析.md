# Nova3 ç³»ç»Ÿæ¶æ„å…¨é¢åˆ†æ

## ğŸ“‹ æ¦‚è¿°

Nova3æ˜¯ä¸€ä¸ªåŸºäºé˜Ÿåˆ—çš„æ™ºèƒ½ä½“ç¼–æ’ç³»ç»Ÿï¼Œé‡‡ç”¨å¼‚æ­¥æ¶æ„è®¾è®¡ï¼Œæ”¯æŒå¤šç§AIä»»åŠ¡çš„æµå¼å¤„ç†ã€‚æœ¬æ–‡æ¡£è¯¦ç»†åˆ†æå…¶æ¶æ„ç‰¹ç‚¹ã€å¹¶å‘èƒ½åŠ›ã€é£é™©ç‚¹å’Œæ‰©å®¹ç­–ç•¥ã€‚

## ğŸ—ï¸ æ ¸å¿ƒæ¶æ„

### 1. ç³»ç»Ÿç»„ä»¶æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Nova3 Supervisor                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Queue Manager â”‚  â”‚   Sub Agents    â”‚  â”‚ LLM Client   â”‚ â”‚
â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚              â”‚ â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚ â”‚Memory Cache â”‚ â”‚  â”‚ â”‚ProfileAgent â”‚ â”‚  â”‚ â”‚OpenAI APIâ”‚ â”‚ â”‚
â”‚  â”‚ â”‚File Persist â”‚ â”‚  â”‚ â”‚InsightAgent â”‚ â”‚  â”‚ â”‚LangSmith â”‚ â”‚ â”‚
â”‚  â”‚ â”‚Thread Lock  â”‚ â”‚  â”‚ â”‚FactsAgent  â”‚ â”‚  â”‚ â”‚Streaming â”‚ â”‚ â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â”‚HitpointAgentâ”‚ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚                 â”‚  â”‚ â”‚XHSWriting   â”‚ â”‚  â”‚              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                      â”‚
         â–¼                       â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   File System   â”‚    â”‚  External APIs  â”‚    â”‚   Web Search    â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ Queue Files     â”‚    â”‚ OpenAI GPT      â”‚    â”‚ Jina Search     â”‚
â”‚ Conversation    â”‚    â”‚ LangSmith       â”‚    â”‚ XHS Search      â”‚
â”‚ History         â”‚    â”‚ Tracking        â”‚    â”‚ DY Search       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. æ•°æ®æµæ¶æ„

```
User Request â†’ Supervisor â†’ Queue Manager â†’ Sub Agent â†’ LLM â†’ Stream Response
     â”‚              â”‚            â”‚             â”‚         â”‚          â”‚
     â”‚              â”‚            â”‚             â”‚         â”‚          â”‚
     â–¼              â–¼            â–¼             â–¼         â–¼          â–¼
Request Data â†’ Task Planning â†’ Task Queue â†’ Agent Exec â†’ Result â†’ User
     â”‚              â”‚            â”‚             â”‚         â”‚          â”‚
     â”‚              â”‚            â”‚             â”‚         â”‚          â”‚
     â–¼              â–¼            â–¼             â–¼         â–¼          â–¼
Nova3 Selections â†’ Enhanced Input â†’ Persistence â†’ Context â†’ LangSmith â†’ Frontend
```

## âš¡ å¹¶å‘èƒ½åŠ›åˆ†æ

### 1. å½“å‰å¹¶å‘é™åˆ¶

#### å•æœºé…ç½®ï¼ˆ8æ ¸CPUï¼Œ16GBå†…å­˜ï¼‰

| ç»„ä»¶ | å¹¶å‘é™åˆ¶ | ç“¶é¢ˆåˆ†æ |
|------|----------|----------|
| **FastAPI/Uvicorn** | ~200-500å¹¶å‘è¿æ¥ | åŸºäºäº‹ä»¶å¾ªç¯çš„å¼‚æ­¥å¤„ç† |
| **Queue Manager** | ~100ä¸ªæ´»è·ƒé˜Ÿåˆ— | å†…å­˜ç¼“å­˜é™åˆ¶ |
| **Sub Agents** | æŒ‰éœ€åˆ›å»ºï¼Œæ— ç¡¬é™åˆ¶ | å—LLM APIé™åˆ¶ |
| **LLM Client** | ~10-20 RPM | OpenAI APIé€Ÿç‡é™åˆ¶ |
| **File I/O** | ~1000 IOPS | SSDæ€§èƒ½é™åˆ¶ |
| **Memory Usage** | ~8-12GBå¯ç”¨ | é˜Ÿåˆ—ç¼“å­˜+æ¨¡å‹åŠ è½½ |

#### ç†è®ºå¹¶å‘è®¡ç®—

```python
# åŸºäº8æ ¸16GBé…ç½®çš„ç†è®ºå¹¶å‘èƒ½åŠ›
CPU_CORES = 8
MEMORY_GB = 16
AVG_REQUEST_TIME = 10  # ç§’
AVG_MEMORY_PER_REQUEST = 50  # MB

# CPUå¯†é›†å‹ä»»åŠ¡å¹¶å‘æ•°
cpu_concurrent = CPU_CORES * 2  # 16ä¸ªå¹¶å‘ä»»åŠ¡

# å†…å­˜é™åˆ¶çš„å¹¶å‘æ•°  
memory_concurrent = (MEMORY_GB * 1024) // AVG_MEMORY_PER_REQUEST  # 320ä¸ª

# å®é™…å¹¶å‘æ•°å—LLM APIé™åˆ¶
actual_concurrent = min(20, cpu_concurrent, memory_concurrent)  # 20ä¸ª
```

### 2. æ€§èƒ½ç“¶é¢ˆåˆ†æ

#### ä¸»è¦ç“¶é¢ˆç‚¹

1. **LLM APIè°ƒç”¨**
   - OpenAI API: 3-10ç§’å“åº”æ—¶é—´
   - é€Ÿç‡é™åˆ¶: 10-20 RPM
   - ç½‘ç»œå»¶è¿Ÿ: 100-500ms

2. **é˜Ÿåˆ—ç®¡ç†**
   - æ–‡ä»¶I/O: æ¯æ¬¡ä¿å­˜5-10ms
   - å†…å­˜é”ç«äº‰: é«˜å¹¶å‘æ—¶æ€§èƒ½ä¸‹é™
   - ç¼“å­˜å‘½ä¸­ç‡: å½±å“å“åº”é€Ÿåº¦

3. **æœç´¢æœåŠ¡**
   - å¤–éƒ¨APIè°ƒç”¨: 2-8ç§’
   - ç½‘ç»œè¶…æ—¶: å¯èƒ½å¯¼è‡´ä»»åŠ¡å¤±è´¥
   - æœç´¢ç»“æœè§£æ: CPUå¯†é›†

## ğŸš¨ é£é™©ç‚¹åˆ†æ

### 1. é«˜é£é™©ç‚¹

#### 1.1 å•ç‚¹æ•…éšœ
```python
# é£é™©ä»£ç ç¤ºä¾‹
class QueueManager:
    def __init__(self):
        self.memory_cache = {}  # å•å®ä¾‹å†…å­˜ï¼Œé‡å¯ä¸¢å¤±
        self.cache_lock = threading.RLock()  # å…¨å±€é”ï¼Œå¯èƒ½æ­»é”
```

**é£é™©**:
- è¿›ç¨‹é‡å¯å¯¼è‡´å†…å­˜é˜Ÿåˆ—ä¸¢å¤±
- å…¨å±€é”åœ¨é«˜å¹¶å‘ä¸‹å¯èƒ½æ­»é”
- æ–‡ä»¶ç³»ç»Ÿæ•…éšœå¯¼è‡´æŒä¹…åŒ–å¤±è´¥

#### 1.2 èµ„æºæ³„æ¼
```python
# æ½œåœ¨æ³„æ¼ç‚¹
async def process_request(self, request_data):
    # LLMå®¢æˆ·ç«¯è¿æ¥æœªæ­£ç¡®å…³é—­
    async for chunk in self.llm_client.stream_chat(messages):
        # å¼‚å¸¸æ—¶å¯èƒ½å¯¼è‡´è¿æ¥æ³„æ¼
        yield chunk
```

**é£é™©**:
- HTTPè¿æ¥æ± è€—å°½
- æ–‡ä»¶å¥æŸ„æ³„æ¼
- å†…å­˜ç¼“å­˜æ— é™å¢é•¿

#### 1.3 å¤–éƒ¨ä¾èµ–æ•…éšœ
```python
# å¤–éƒ¨ä¾èµ–é£é™©
dependencies = {
    "openai_api": {"timeout": 30, "retry": 3},
    "langsmith": {"fallback": True},
    "search_apis": {"timeout": 10, "retry": 2}
}
```

**é£é™©**:
- OpenAI APIæœåŠ¡ä¸­æ–­
- æœç´¢æœåŠ¡ä¸å¯ç”¨
- LangSmithè¿½è¸ªå¤±è´¥

### 2. ä¸­ç­‰é£é™©ç‚¹

#### 2.1 å†…å­˜ä½¿ç”¨
- é˜Ÿåˆ—ç¼“å­˜å¯èƒ½æ— é™å¢é•¿
- å¤§å‹æœç´¢ç»“æœå ç”¨è¿‡å¤šå†…å­˜
- ä¼šè¯å†å²ç§¯ç´¯è¿‡å¤š

#### 2.2 å¹¶å‘æ§åˆ¶
- é˜Ÿåˆ—é”ç«äº‰
- æ–‡ä»¶å†™å…¥å†²çª
- IDç”Ÿæˆå™¨å¹¶å‘å®‰å…¨

#### 2.3 æ•°æ®ä¸€è‡´æ€§
- é˜Ÿåˆ—çŠ¶æ€ä¸ä¸€è‡´
- ä»»åŠ¡é‡å¤æ‰§è¡Œ
- å†å²æ•°æ®æŸå

## ğŸ›¡ï¸ é™çº§ç­–ç•¥

### 1. æœåŠ¡é™çº§ç­–ç•¥

#### 1.1 LLMæœåŠ¡é™çº§
```python
class LLMFallbackStrategy:
    def __init__(self):
        self.primary_model = "gpt-3.5-turbo"
        self.fallback_model = "gpt-3.5-turbo-instruct"
        self.local_model = None  # å¯é€‰æœ¬åœ°æ¨¡å‹
    
    async def call_with_fallback(self, messages):
        try:
            return await self.call_primary(messages)
        except OpenAIError:
            try:
                return await self.call_fallback(messages)
            except Exception:
                return await self.call_local_model(messages)
```

#### 1.2 æœç´¢æœåŠ¡é™çº§
```python
class SearchFallbackStrategy:
    search_services = [
        "jina_search",    # ä¸»è¦æœåŠ¡
        "xhs_search",     # å¤‡ç”¨æœåŠ¡
        "cached_results"  # ç¼“å­˜ç»“æœ
    ]
    
    async def search_with_fallback(self, query):
        for service in self.search_services:
            try:
                return await self.call_service(service, query)
            except Exception:
                continue
        return self.get_default_results()
```

### 2. èµ„æºä¿æŠ¤ç­–ç•¥

#### 2.1 å†…å­˜ä¿æŠ¤
```python
class MemoryProtection:
    MAX_QUEUE_SIZE = 1000
    MAX_CACHE_SIZE = 100
    MEMORY_THRESHOLD = 0.8  # 80%å†…å­˜ä½¿ç”¨ç‡
    
    def check_memory_usage(self):
        if psutil.virtual_memory().percent > self.MEMORY_THRESHOLD:
            self.emergency_cleanup()
    
    def emergency_cleanup(self):
        # æ¸…ç†æœ€è€çš„é˜Ÿåˆ—
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        # é™åˆ¶æ–°è¯·æ±‚
```

#### 2.2 è¿æ¥æ± ç®¡ç†
```python
class ConnectionPoolManager:
    def __init__(self):
        self.max_connections = 50
        self.timeout = 30
        self.retry_times = 3
    
    async def get_connection(self):
        # è¿æ¥æ± ç®¡ç†
        # è¶…æ—¶æ§åˆ¶
        # é‡è¯•æœºåˆ¶
```

### 3. ç†”æ–­ç­–ç•¥

#### 3.1 APIç†”æ–­
```python
class CircuitBreaker:
    def __init__(self, failure_threshold=5, timeout=60):
        self.failure_count = 0
        self.failure_threshold = failure_threshold
        self.timeout = timeout
        self.last_failure_time = None
        self.state = "CLOSED"  # CLOSED, OPEN, HALF_OPEN
    
    async def call(self, func, *args, **kwargs):
        if self.state == "OPEN":
            if time.time() - self.last_failure_time > self.timeout:
                self.state = "HALF_OPEN"
            else:
                raise CircuitBreakerOpenError()
        
        try:
            result = await func(*args, **kwargs)
            self.on_success()
            return result
        except Exception as e:
            self.on_failure()
            raise
```

## ğŸ“ˆ æ‰©å®¹ç­–ç•¥

### 1. å‚ç›´æ‰©å®¹ï¼ˆå•æœºä¼˜åŒ–ï¼‰

#### 1.1 ç¡¬ä»¶å‡çº§å»ºè®®
```yaml
# æ¨èé…ç½®
cpu: 16-32æ ¸
memory: 32-64GB
storage: NVMe SSD 1TB+
network: 1Gbps+

# æ€§èƒ½æå‡é¢„æœŸ
concurrent_requests: 50-100ä¸ª
response_time: å‡å°‘30-50%
throughput: æå‡2-3å€
```

#### 1.2 è½¯ä»¶ä¼˜åŒ–
```python
# å¼‚æ­¥ä¼˜åŒ–
class OptimizedSupervisor:
    def __init__(self):
        # è¿æ¥æ± ä¼˜åŒ–
        self.llm_client = AsyncLLMClient(
            max_connections=20,
            connection_pool_size=50
        )
        
        # é˜Ÿåˆ—ä¼˜åŒ–
        self.queue_manager = AsyncQueueManager(
            max_cache_size=500,
            batch_size=10
        )
        
        # å¹¶å‘æ§åˆ¶
        self.semaphore = asyncio.Semaphore(30)
```

### 2. æ°´å¹³æ‰©å®¹ï¼ˆå¤šæœºéƒ¨ç½²ï¼‰

#### 2.1 æ¶æ„æ”¹é€ éœ€æ±‚

##### çŠ¶æ€åˆ†ç¦»
```python
# å½“å‰é—®é¢˜ï¼šçŠ¶æ€å­˜å‚¨åœ¨æœ¬åœ°
class QueueManager:
    def __init__(self):
        self.memory_cache = {}  # æœ¬åœ°å†…å­˜
        self.persist_dir = "data/nova3_queues"  # æœ¬åœ°æ–‡ä»¶

# æ”¹é€ æ–¹æ¡ˆï¼šå¤–éƒ¨çŠ¶æ€å­˜å‚¨
class DistributedQueueManager:
    def __init__(self):
        self.redis_client = Redis(host="redis-cluster")
        self.db_client = AsyncPostgreSQL()
        self.cache_client = Memcached()
```

##### è´Ÿè½½å‡è¡¡
```yaml
# Nginxé…ç½®
upstream nova3_backend {
    server nova3-1:8000 weight=1;
    server nova3-2:8000 weight=1;
    server nova3-3:8000 weight=1;
}

server {
    location /nova3/ {
        proxy_pass http://nova3_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

#### 2.2 åˆ†å¸ƒå¼æ”¹é€ æ–¹æ¡ˆ

##### é˜Ÿåˆ—ç®¡ç†æ”¹é€ 
```python
class DistributedQueueManager:
    def __init__(self):
        self.redis = aioredis.Redis.from_url("redis://cluster")
        self.db = AsyncPostgreSQL()
    
    async def get_queue(self, user_id: str, session_id: str):
        # å…ˆæŸ¥Redisç¼“å­˜
        cache_key = f"queue:{user_id}:{session_id}"
        cached = await self.redis.get(cache_key)
        if cached:
            return TaskQueue.parse_raw(cached)
        
        # å†æŸ¥æ•°æ®åº“
        queue = await self.db.fetch_queue(user_id, session_id)
        if queue:
            # å†™å…¥ç¼“å­˜
            await self.redis.setex(cache_key, 3600, queue.json())
        
        return queue
    
    async def save_queue(self, queue: TaskQueue):
        # åŒæ—¶å†™å…¥Rediså’Œæ•°æ®åº“
        cache_key = f"queue:{queue.user_id}:{queue.session_id}"
        await asyncio.gather(
            self.redis.setex(cache_key, 3600, queue.json()),
            self.db.save_queue(queue)
        )
```

##### ä¼šè¯äº²å’Œæ€§
```python
class SessionAffinityManager:
    def __init__(self):
        self.node_mapping = {}  # session_id -> node_id
    
    def get_target_node(self, session_id: str) -> str:
        # åŸºäºsession_idçš„ä¸€è‡´æ€§å“ˆå¸Œ
        hash_value = hashlib.md5(session_id.encode()).hexdigest()
        node_index = int(hash_value, 16) % len(self.available_nodes)
        return self.available_nodes[node_index]
```

#### 2.3 æ•°æ®åº“è®¾è®¡

##### é˜Ÿåˆ—è¡¨ç»“æ„
```sql
-- ä»»åŠ¡é˜Ÿåˆ—è¡¨
CREATE TABLE nova3_queues (
    id SERIAL PRIMARY KEY,
    queue_key VARCHAR(255) UNIQUE NOT NULL,
    user_id VARCHAR(100) NOT NULL,
    session_id VARCHAR(100) NOT NULL,
    current_task_index INTEGER DEFAULT 0,
    created_at TIMESTAMP DEFAULT NOW(),
    last_accessed TIMESTAMP DEFAULT NOW(),
    INDEX idx_user_session (user_id, session_id),
    INDEX idx_last_accessed (last_accessed)
);

-- ä»»åŠ¡è¡¨
CREATE TABLE nova3_tasks (
    id SERIAL PRIMARY KEY,
    queue_id INTEGER REFERENCES nova3_queues(id),
    task_id VARCHAR(50) NOT NULL,
    action VARCHAR(50) NOT NULL,
    input TEXT NOT NULL,
    status VARCHAR(20) DEFAULT 'pending',
    result TEXT,
    created_at TIMESTAMP DEFAULT NOW(),
    completed_at TIMESTAMP,
    INDEX idx_queue_id (queue_id),
    INDEX idx_status (status)
);
```

### 3. å¾®æœåŠ¡æ¶æ„

#### 3.1 æœåŠ¡æ‹†åˆ†æ–¹æ¡ˆ
```yaml
# æœåŠ¡æ¶æ„
services:
  nova3-gateway:
    - è¯·æ±‚è·¯ç”±
    - è´Ÿè½½å‡è¡¡
    - è®¤è¯æˆæƒ
  
  nova3-supervisor:
    - ä»»åŠ¡ç¼–æ’
    - è®¡åˆ’ç”Ÿæˆ
    - æµç¨‹æ§åˆ¶
  
  nova3-queue-service:
    - é˜Ÿåˆ—ç®¡ç†
    - çŠ¶æ€æŒä¹…åŒ–
    - ä»»åŠ¡è°ƒåº¦
  
  nova3-agent-service:
    - å­Agentæ‰§è¡Œ
    - ç»“æœå¤„ç†
    - é”™è¯¯æ¢å¤
  
  nova3-llm-service:
    - LLMè°ƒç”¨
    - æµå¼å¤„ç†
    - è¿½è¸ªè®°å½•
```

#### 3.2 å®¹å™¨åŒ–éƒ¨ç½²
```dockerfile
# Nova3 Supervisor
FROM python:3.11-slim
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . /app
WORKDIR /app
EXPOSE 8000
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

```yaml
# Docker Compose
version: '3.8'
services:
  nova3-supervisor:
    build: .
    ports:
      - "8000:8000"
    environment:
      - REDIS_URL=redis://redis:6379
      - DATABASE_URL=postgresql://user:pass@postgres:5432/nova3
    depends_on:
      - redis
      - postgres
  
  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data
  
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: nova3
      POSTGRES_USER: user
      POSTGRES_PASSWORD: pass
    volumes:
      - postgres_data:/var/lib/postgresql/data
```

## ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•

### 1. å•æœºæ€§èƒ½åŸºå‡†

| æŒ‡æ ‡ | å½“å‰å€¼ | ä¼˜åŒ–å | åˆ†å¸ƒå¼ |
|------|--------|--------|--------|
| **å¹¶å‘è¯·æ±‚æ•°** | 10-20 | 50-100 | 200-500 |
| **å¹³å‡å“åº”æ—¶é—´** | 15-30ç§’ | 8-15ç§’ | 5-10ç§’ |
| **ååé‡(RPS)** | 1-2 | 5-10 | 20-50 |
| **å†…å­˜ä½¿ç”¨** | 2-4GB | 4-8GB | 1-2GB/èŠ‚ç‚¹ |
| **CPUä½¿ç”¨ç‡** | 30-60% | 50-80% | 40-70% |

### 2. æ‰©å®¹å»ºè®®

#### 2.1 çŸ­æœŸä¼˜åŒ–ï¼ˆ1-2å‘¨ï¼‰
- å¢åŠ è¿æ¥æ± å¤§å°
- ä¼˜åŒ–ç¼“å­˜ç­–ç•¥
- æ·»åŠ ç†”æ–­æœºåˆ¶
- ç›‘æ§å‘Šè­¦ç³»ç»Ÿ

#### 2.2 ä¸­æœŸæ”¹é€ ï¼ˆ1-2æœˆï¼‰
- Redisé›†ç¾¤éƒ¨ç½²
- æ•°æ®åº“è¯»å†™åˆ†ç¦»
- å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—
- å®¹å™¨åŒ–éƒ¨ç½²

#### 2.3 é•¿æœŸæ¶æ„ï¼ˆ3-6æœˆï¼‰
- å¾®æœåŠ¡æ‹†åˆ†
- æœåŠ¡ç½‘æ ¼
- è‡ªåŠ¨æ‰©ç¼©å®¹
- å¤šåŒºåŸŸéƒ¨ç½²

## ğŸ”§ å®æ–½å»ºè®®

### 1. ç«‹å³å®æ–½ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰

#### 1.1 æ·»åŠ ç›‘æ§å’Œå‘Šè­¦
```python
# æ€§èƒ½ç›‘æ§
import psutil
import time
from prometheus_client import Counter, Histogram, Gauge

class PerformanceMonitor:
    def __init__(self):
        self.request_count = Counter('nova3_requests_total', 'Total requests')
        self.request_duration = Histogram('nova3_request_duration_seconds', 'Request duration')
        self.memory_usage = Gauge('nova3_memory_usage_bytes', 'Memory usage')
        self.active_queues = Gauge('nova3_active_queues', 'Active queues')
    
    def record_request(self, duration: float):
        self.request_count.inc()
        self.request_duration.observe(duration)
    
    def update_system_metrics(self):
        self.memory_usage.set(psutil.virtual_memory().used)
        self.active_queues.set(len(self.queue_manager.memory_cache))
```

#### 1.2 æ·»åŠ ç†”æ–­æœºåˆ¶
```python
# åœ¨supervisor.pyä¸­æ·»åŠ 
class Nova3Supervisor(BaseAgent):
    def __init__(self):
        super().__init__("nova3_supervisor")
        self.circuit_breaker = CircuitBreaker()
        self.performance_monitor = PerformanceMonitor()
    
    async def process_request(self, request_data, context):
        start_time = time.time()
        try:
            async for event in self.circuit_breaker.call(
                self._process_request_internal, request_data, context
            ):
                yield event
        finally:
            duration = time.time() - start_time
            self.performance_monitor.record_request(duration)
```

### 2. è¿‘æœŸå®æ–½ï¼ˆä¸­ä¼˜å…ˆçº§ï¼‰

#### 2.1 Redisé›†æˆ
```python
# æ–°å¢redis_queue_manager.py
class RedisQueueManager(QueueManager):
    def __init__(self, redis_url: str):
        self.redis = aioredis.from_url(redis_url)
        super().__init__()
    
    async def get_queue(self, user_id: str, session_id: str) -> Optional[TaskQueue]:
        # Redis + æœ¬åœ°ç¼“å­˜åŒå±‚ç­–ç•¥
        cache_key = f"nova3:queue:{user_id}:{session_id}"
        
        # å…ˆæŸ¥æœ¬åœ°ç¼“å­˜
        queue = super().get_queue(user_id, session_id)
        if queue:
            return queue
        
        # å†æŸ¥Redis
        cached_data = await self.redis.get(cache_key)
        if cached_data:
            queue_data = json.loads(cached_data)
            queue = TaskQueue(**queue_data)
            self._add_to_cache(queue.queue_key, queue)
            return queue
        
        return None
```

### 3. é•¿æœŸè§„åˆ’ï¼ˆä½ä¼˜å…ˆçº§ï¼‰

#### 3.1 å¾®æœåŠ¡æ¶æ„è®¾è®¡
- API Gateway
- æœåŠ¡å‘ç°
- é…ç½®ä¸­å¿ƒ
- é“¾è·¯è¿½è¸ª

#### 3.2 äº‘åŸç”Ÿéƒ¨ç½²
- Kubernetes
- Helm Charts
- CI/CD Pipeline
- è‡ªåŠ¨æ‰©ç¼©å®¹

## ğŸ“ æ€»ç»“

Nova3ç³»ç»Ÿå½“å‰åœ¨å•æœº8æ ¸16GBé…ç½®ä¸‹ï¼Œç†è®ºå¹¶å‘èƒ½åŠ›çº¦ä¸º**20ä¸ªåŒæ—¶è¯·æ±‚**ï¼Œä¸»è¦å—é™äºLLM APIè°ƒç”¨ã€‚é€šè¿‡ä¼˜åŒ–å¯æå‡è‡³**50-100ä¸ªå¹¶å‘**ï¼Œåˆ†å¸ƒå¼éƒ¨ç½²åå¯è¾¾åˆ°**200-500ä¸ªå¹¶å‘**ã€‚

**å…³é”®æ”¹è¿›ç‚¹**ï¼š
1. æ·»åŠ Redisç¼“å­˜å±‚
2. å®æ–½ç†”æ–­å’Œé™çº§æœºåˆ¶
3. ä¼˜åŒ–å¼‚æ­¥å¤„ç†æµç¨‹
4. å®¹å™¨åŒ–å’Œå¾®æœåŠ¡æ”¹é€ 

**é£é™©æ§åˆ¶**ï¼š
1. å¤–éƒ¨ä¾èµ–æ•…éšœå¤„ç†
2. å†…å­˜å’Œè¿æ¥æ³„æ¼é˜²æŠ¤
3. æ•°æ®ä¸€è‡´æ€§ä¿éšœ
4. æ€§èƒ½ç›‘æ§å’Œå‘Šè­¦

é€šè¿‡åˆ†é˜¶æ®µå®æ–½ï¼Œå¯ä»¥åœ¨ä¿è¯ç³»ç»Ÿç¨³å®šæ€§çš„å‰æä¸‹ï¼Œé€æ­¥æå‡Nova3çš„å¹¶å‘å¤„ç†èƒ½åŠ›å’Œå¯æ‰©å±•æ€§ã€‚
