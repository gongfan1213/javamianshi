## BluePlan Research 项目里针对“大模型输出不稳定”的容错设计与实现

本文聚焦项目在“大模型输出不稳定/格式漂移/工具调用混乱/链路中断”等场景下的工程级容错方案，系统梳理“协议约束 → 解析容错 → 链路恢复 → 可观测与降级”的全链路策略，并说明“为什么这样处理”。

### 1) 目标与常见不稳定症状

- 目标
  - 保证前端渲染协议不崩溃（统一 `StreamEvent`）。
  - 保证流式链路不悬挂（标准 `[DONE]` 结束信号）。
  - 保证断线可恢复（回放+实时混合模式）。
  - 容忍 LLM 输出格式错误（标签错拼、未闭合、大小写不统一、混杂内容等）。
  - 工具调用安全（并发隔离、权限/所有权校验、超时与失败不阻塞主流程）。
  - 降级不中断（Redis 不可用、限流服务异常等保证业务继续）。

- 典型不稳定输出
  - XML 标签不闭合/大小写错误/拼写错误/嵌套错位。
  - 带序号标签的序号不匹配（如 `<confirm1>...</confirm2>`）。
  - 全输出都是标签，剥离后文本为空。
  - 混合自然语言+标签，或夹带确认性废话（“好的，收到您的指令”）。
  - 工具调用结果结构不稳定（为空/字段缺失）。

---

### 2) 统一协议与边界收口：SSE + 强类型事件

- 统一的流式事件协议（`StreamEvent/EventType/ContentType`）确保前端“收到什么就能稳定渲染”。

```287:293:apis/schemas.py
class StreamEvent(BaseModel):
    event_type: EventType
    agent_source: str
    timestamp: str = Field(default_factory=lambda: datetime.now().isoformat())
    payload: EventPayload
```

- 所有流都以 `[DONE]` 结束，防止前端流悬挂。
```771:773:apis/routes.py
# ... 发送完成事件
yield "[DONE]\n\n"
```

- 为什么这样做
  - 以“协议优先”而非“解析优先”设计，任何 Agent/工具变化都不影响前端契约。
  - `[DONE]` 是前端关闭事件源的硬条件，必须强制发送。

---

### 3) 路由层保护：会话一致性、错误兜底与可重放

- 会话一致性校验：清理跨会话引用，避免污染上下文。
```116:159:apis/routes.py
if request.request_data.references:
    ...
    note = await persistence_manager.get_note_by_name(current_user_id, current_session_id, note_name)
    if note: cleaned_refs.append(ref)
    else: invalid_refs.append(ref)
```

- 严格兜底：错误事件 + 飞书告警 + 仍发送 DONE。
```481:508:apis/routes.py
error_event = StreamEvent(event_type=EventType.ERROR, ...)
yield f"{error_event.model_dump_json()}\n\n"
# 即使出错也发送DONE标记
yield "[DONE]\n\n"
```

- 智能回放/混合流：断开后回放历史，再无缝切到实时流；所有分支都发 `[DONE]`。
```327:372:apis/recovery_routes_simple.py
# Phase 1: 回放历史事件
# ...
# Phase 2: 切换到实时流
# ...
yield "[DONE]\n\n"
```

- 为什么这样做
  - “先清理再处理”能阻断跨会话污染引发的诡异问题。
  - “错误也要 DONE”防止前端等待卡死。
  - 混合回放是断线恢复的最佳实践：用户体验无缝且不丢事件。

---

### 4) 中间件层保护：鉴权/限流与降级

- 仅对白名单接口强制鉴权+限流；限流查询异常时放行，避免“护栏服务问题”影响主流程。
```161:167:apis/app.py
except Exception as e:
    logger.error(f"限流检查异常: {e}")
    # 限流检查失败时，为了系统稳定性，允许请求继续
```

- 发送限流告警但不阻断业务（异步）。
```123:137:apis/app.py
asyncio.create_task(alert_manager.send_rate_limit_alert(...))
```

- 为什么这样做
  - 限流系统本身不可成为单点。
  - 鉴权/限流问题不应劣化为“服务不可用”。

---

### 5) Concierge 的“强容错”解析与工具编排

#### 5.1 过滤确认性输入（避免污染上下文）

```365:382:agents/loomi/concierge.py
confirmation_inputs = ["I'm done", "i'm done", "我选好了"]
is_confirmation = any(... in query.lower())
if is_confirmation:
    ...
```

- 为什么这样做
  - 把“响应性确认”从“业务内容”剥离，避免干扰上下文记忆与后续执行。

#### 5.2 XML 标签全链路容错（拼写、大小写、不闭合、序号错等）

- 总调度：集中处理四类标签，返回“处理后文本 + 待触发动作”。
```769:801:agents/loomi/concierge.py
processed_text, remaining_text, orchestrator_calls, web_search_calls = await self._process_xml_tags(...)
```

- create_note：标准提取后替换为用户友好文本，避免前端渲染失控。
```803:842:agents/loomi/concierge.py
pattern = r'<create_note> ... </create_note>'
success = await self.create_note(...)
processed_text = re.sub(full_pattern, replacement, processed_text, flags=re.DOTALL)
```

- save_material：多模式容错解析（大小写、缺少 id/content、不闭合等），并规范命名为 `material{id}`。
```1711:1837:agents/loomi/concierge.py
matches = self._parse_save_material_with_fallback(text)
# 兼容 ID/CONTENT 大小写、缺字段、未闭合等
```

- call_orchestrator：预处理常见拼写（`call_orcheator` 等），多种正则回退，未闭合时智能移除。
```1838:1867:agents/loomi/concierge.py
fixed_text = re.sub(r'<call_orcheator>', '<call_orchestrator>', fixed_text, ...)
```
```1869:1913:agents/loomi/concierge.py
# patterns 覆盖标准/到文本结尾/被分割等场景
found_matches = re.findall(...)
```

- confirm 分段解析：标准+容错模式；若不存在 confirm，按段落拆分为 message。
```1505:1609:agents/loomi/concierge.py
confirm_pattern = r'<confirm(\d+)>(.*?)</confirm\1>'
if not confirm_matches:
    confirm_matches = self._parse_confirm_tags_with_fallback(response)
# 否则按段落切 message
```

- 为什么这样做
  - LLM 的“工具协议输出”经常偏离格式，必须“强容错 + 强约束”才能稳定落地。
  - “先预处理再解析”能最大化恢复结构，兜底避免丢信息。
  - 解析后“替换为用户友好文本”可避免前端渲染奇怪 XML 与破布局。

#### 5.3 并行工具的安全性与降级

- 并行搜索：`asyncio.gather(return_exceptions=True)`，逐任务隔离，失败不拖垮总流程；结果字段统一为前端要求的 5 项。
```989:1012:agents/loomi/concierge.py
search_responses = await asyncio.gather(*tasks, return_exceptions=True)
# 合并成功结果，失败记录 warning
```
```1074:1101:agents/loomi/concierge.py
formatted_result = {"title","link","content","icon","publish_date"}
```

- 重新分析：基于搜索结果再次构建上下文，避免“一次答完”的偏差。
```1103:1186:agents/loomi/concierge.py
re_analysis_items = self._parse_concierge_response(...)
yield await self.emit_loomi_event(..., re_analysis_items, ...)
```

- Orchestrator 委派：记录调用、转发其流式事件，失败回写用户可读错误但整体流不崩。
```1407:1470:agents/loomi/concierge.py
async for event in orchestrator.process_request(...): yield event
except Exception: yield ... "❌ 任务委派失败"
```

- 为什么这样做
  - 工具调用失败是常态，隔离/降级是产品体验的底线。
  - “基于新证据的二次分析”是强化事实一致性的关键。

#### 5.4 多模态文件处理的稳健性

- 文件大小上限/扩展名黑名单（上传侧提前拦截）。
```1812:1819:apis/routes.py
forbidden_extensions = {...'.doc','.pptx','.mp4',...}
```
```1910:1916:apis/routes.py
MAX_FILE_SIZE = 10 * 1024 * 1024
```

- 所有权/存在性校验；准备临时文件、Gemini 调用异常兜底、始终清理临时文件。
```1861:1873:apis/routes.py
if not file_info: 404; if user_id mismatch: 403
```
```301:307:agents/loomi/concierge.py
await self.multimodal_processor._cleanup_temp_files(...)
```

- 异常输出“不是有效分析”的提示文本检测，规避“收到您的指令”类伪结果。
```272:279:agents/loomi/concierge.py
if analysis_result.startswith("好的，收到您的指令"): ...
```

- 为什么这样做
  - 上传入口是第一道防线；临时文件清理是必须的稳定性保障。
  - 防“伪分析”是应对通用模型的“接话式错觉”。

---

### 6) 断线恢复与回放标记幂等

- 三模式：无需回放/纯回放/混合（回放后切实时）。
- 所有回放/实时流出的事件都“就地标记为已回放”，避免重复回放。
```258:262:apis/recovery_routes_simple.py
event_ids = [event['id'] for event in new_events]
await persistence_manager.stream_storage.mark_specific_events_replayed(...)
```

- 为什么这样做
  - 保证“拉一次，发一次，标一次”的幂等，防止“鬼畜回放”。

---

### 7) 停止机制与 Redis 降级

- 查询停止状态时：Redis 不可用降级到内存缓存，保证查询接口不崩。
```3058:3094:apis/routes.py
if not manager_status.get("redis_available", True): ... memory_only ...
```

- 批量清除/全清除支持，遇异常也尽量返回“可用的基本信息”。

- 为什么这样做
  - 停止是用户的“紧急刹车”，不可因为外部依赖失败而失效。

---

### 8) 可观测性与健康检查

- 健康检查聚合多层次（文件、Redis、队列、结果管理器、配置），异常不崩接口，返回 degraded/unhealthy。
```179:210:apis/health.py
storage_health["layers"]["redis"] = await _check_redis_storage()
...
storage_health["status"] = "degraded"/"unhealthy"
```

- 请求中间件记录耗时头 `X-Process-Time`，便于端到端监测。
```32:35:apis/middleware.py
response.headers["X-Process-Time"] = str(process_time)
```

- 为什么这样做
  - 可观测性是快速定界的关键，异常要“说得清楚”。

---

### 9) 设计取舍与扩展建议

- 先“收完 LLM 输出再解析”而非“边流边解析”
  - 利：能做复杂容错（回退、纠错、重写），效果稳定。
  - 弊：首字延迟略增；后续可引入“流式 parser”降低 TTFB，同时保留收尾容错。

- ReAct 模式 vs ReWOO
  - 当前 Loomi 走 ReAct（观察-思考-行动），XML 标签承载工具调用协议。若要演进 ReWOO（先规划后并行执行再求解），需在 `schemas` 中扩展 plan/evidence/citation 类型，构建 Planner/Runner/Solver 三段式。

---

### 10) LLM 可能返回的“非标格式”与对应处理表

- 标签不闭合/大小写错/拼写错 → 预处理修正 + 多模式回退解析（create_note/save_material/call_orchestrator/confirm）
- 全标签输出 → 剥离后可能为空 → 视为正常（不强制报错），继续后续工具触发
- 混合文本+标签 → 先解析标签，再把剩余文本按段落拆 message
- 伪响应（“好的，收到您的指令”）→ 识别并警告，不作为有效分析
- 工具并发失败 → 单任务隔离；总体仍给出部分结果 + 继续主流程
- Redis/限流服务异常 → 降级放行/内存模式，不阻断业务
- 断线重连 → 按需回放/混合流；所有分支 `[DONE]`；发出 is_replay/is_realtime/phase 元数据

---

### 结论
- 项目采取“协议优先 + 强容错解析 + 并发隔离 + 链路回放 + 降级不中断”的组合拳，针对 LLM 输出不稳定做了系统性工程强化。
- 关键收益：
  - 前端展示稳定（统一 `StreamEvent`）。
  - 交互不中断（无论失败/断线都 `[DONE]`）。
  - 误格式高容忍（预处理 + 多模式回退）。
  - 工具可观测、失败可降级、状态可诊断。

- 建议的下一步增强：
  - 引入“流式解析器”降低首字延迟。
  - 对多模态按类型细化 Prompt 与指标监控。
  - 规划 ReWOO 的 Planner/Worker/Solver 事件类型与缓存层，实现并行证据执行与答案汇总。

- 关键代码索引
  - `apis/schemas.py`: 事件与类型协议
  - `apis/routes.py`: 会话一致性、SSE 生成器、错误兜底/告警、文件/导出/统计/停止
  - `apis/recovery_routes_simple.py`: 回放/混合流/标记幂等
  - `agents/loomi/concierge.py`: XML 强容错、多模态/搜索/编排
  - `apis/app.py`: 白名单鉴权+限流与降级
  - `apis/health.py`, `apis/middleware.py`: 健康检查、端到端耗时

- 如果需要，我可以把本文保存为仓库根目录的 `LLM_Fault_Tolerance_Design.md`。
