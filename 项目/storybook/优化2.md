你描述的多 Agent 架构相当完善，而且你的背景是“纯调用 API + prompt 驱动”，我们可以针对新增节点（尤其是人物一致性与场景指令结构化）推荐一些免费、开源的模型资源——在 **OpenRouter、ChatGLM、Kimi** 等平台上能接入的。

---

## 1. OpenRouter 上的免费模型（以文本／多模态为主）

OpenRouter 是一个统一 API 网关，汇聚了多个免费模型入口，适合用作 **Story Planning** / **Prompt 编译** / **Story Writing** 等文本任务：

* **meta-llama/llama-4-maverick\:free**：多专家结构，支持 **文本 + 图像 → 文本** 多模态，用于结构化 prompt 生成、故事规划非常适合。([apidog][1])
* **moonshotai/kimi-vl-a3b-thinking\:free**：轻量 MoE 模型，专注视觉推理，适合把场景描述转成结构化表示或校验文本与图像的一致性，也能用于 QA Agent。([apidog][1])

Reddit 用户也推荐 DeepSeek V3 作为可用的文本模型，虽然侧重生成，但质量不错，适用于写故事“流畅性”优化：

> “I’m good thus far with DeepSeek V3 0324. It’s supposedly much better in terms of not being as repetitive...” ([Reddit][2])

---

## 2. 开源模型与技术资源（人物一致性 / 插图风格锁定）

### InstantCharacter（腾讯出品，2025）

一个开源框架，专注于无需微调就能保持**高保真人物一致性**：

* 支持 open-domain 多姿态、风格的角色一致性；
* 使用 adapter + transformer encoder，可在 prompt 中结合文本与视觉特征控制生成；
* 提供源码与模型，适合做 CharacterEmbeddingAgent 或 PromptConditionAgent。([arXiv][3])

### StoryMaker（2024）

一个专注 **整人角色一致性** 的文本到图像生成方法：

* 支持面部、服饰、姿态的整体一致性；
* 结合 LoRA + segmentation 进行风格锁定；
* 非训练时使用（tuning-free），适合加入你现有流程中的 Image Consistency Agent。([arXiv][4])

### FreeU（2023）

一个轻量技巧，不用额外训练即可优化生成质量：

* 通过调整 diffusion U-Net 中 skip connection 与主干的权重，在生成时提升图像质量；
* 能应用在 Stable Diffusion / DreamBooth 等基础模型的 API 生成阶段，提升画面清晰度与风格一致性。([arXiv][5])

---

## 3. ChatGLM、Kimi 上的可选模型

目前公开资料里，关于 ChatGLM / Kimi 上直接用于图像生成的一致性模型较少，主要还是以文本任务为主。如果你能找到这些平台上支持 Visual-LMs，适合调用的方式与 OpenRouter 类似，建议优先考查他们的 **视觉推理 Transformer** 或 **Multimodal LLM** 接入方案。

---

## 综合推荐表

| 节点需求             | 推荐模型 / 技术                           | 说明                                    |
| ---------------- | ----------------------------------- | ------------------------------------- |
| 故事规划、文本生成        | meta-llama-4-maverick 或 DeepSeek V3 | 免费 OpenRouter 接入，支持长 context 文本与场景结构化 |
| 把场景描述结构化为 prompt | moonshotai/kimi-vl-a3b              | 擅视觉映射，适合指令结构化生成                       |
| 人物一致性控制          | InstantCharacter / StoryMaker       | 一致性强，无需大规模微调                          |
| 提升图像质量与视觉一致性     | FreeU 技巧                            | 简单插入即可改善生成画质，兼容主流 diffusion 模型        |

---

## 下一步建议

1. **Text Agent 优化**：用 OpenRouter 的 **llama-4-maverick** 作为 StoryPlanner 或 PromptCompiler 的基础模型；同时尝试 **kimi-vl** 用于场景结构化。
2. **Character Agent**：评估 InstantCharacter 或 StoryMaker 是否能无缝集成进流程，用以人物一致性，无需昂贵微调。
3. **图像质量提升**：如果你的 ImageGenerator 跑的是如 Stable Diffusion 类型的模型，可插入 **FreeU** 技术提升结果。
4. **跑个原型测试**：写个小流程 demo，比如一句话描述 + 2–3 页生成，快速验证一致性控制是否有效。

如果你想，我可以帮你画一个包含这些推荐模型的新 Agent 架构图，或帮你写一个伪代码样例说明如何调用这些免费资源。想继续做哪一个？让我知道，我来继续深入帮你！

[1]: https://apidog.com/blog/free-ai-models/?utm_source=chatgpt.com "Best Free AI Models You Can Use on OpenRouter"
[2]: https://www.reddit.com/r/AgnAIstic/comments/1jpxmy0/whats_the_best_free_openrouter_model/?utm_source=chatgpt.com "What's the best free openrouter model? : r/AgnAIstic - Reddit"
[3]: https://arxiv.org/abs/2504.12395?utm_source=chatgpt.com "InstantCharacter: Personalize Any Characters with a Scalable Diffusion Transformer Framework"
[4]: https://arxiv.org/abs/2409.12576?utm_source=chatgpt.com "StoryMaker: Towards Holistic Consistent Characters in Text-to-image Generation"
[5]: https://arxiv.org/abs/2309.11497?utm_source=chatgpt.com "FreeU: Free Lunch in Diffusion U-Net"
