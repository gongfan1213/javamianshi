# qspace状态管理系统

id,text.type.status.initial,children

图谱式的qpase的结构的

nodes,id,label.data:type。descriprion,
edges,source,target,label


状态管理机制，
文件路径机制

q_space状态流转：initial刚刚创建的问题节点。open等待处理的问题，in_progress正在处理的

answered已经解答的，confilited存在冲突需要解决的c.losed已经关闭的


# wisebase状态管理系统哦难过

创建，分类，关联qspace，跨部门共享，归档

创建时间戳，来源部门表示，置信度评分，关联的qspace节点的


内存存储

store_type.file_path

内存字典存储的，

知识分类：fact,hypothesis,point,context上下文信息爹，

qspace持久话的。json文件持久话时机的，每次更新q-space的时候立即写入的

```
from enum import Enum
from typing import Dict, Any, Callable

class ExecutionMode(Enum):
    SEQUENTIAL = "sequential"
    PARALLEL = "parallel"
    ASYNC = "async"
    ADVANCED = "advanced"

class AnalysisExecutor:
    """分析执行器 - 支持多种执行模式"""
    
    def __init__(self, mode: ExecutionMode = ExecutionMode.PARALLEL):
        self.mode = mode
        self.execution_strategies = {
            ExecutionMode.SEQUENTIAL: self._run_sequential,
            ExecutionMode.PARALLEL: self._run_parallel,
            ExecutionMode.ASYNC: self._run_async,
            ExecutionMode.ADVANCED: self._run_advanced
        }
    
    def run_analysis(self, crews: Dict[str, Any]) -> Dict[str, Any]:
        """根据配置的模式执行分析"""
        strategy = self.execution_strategies.get(self.mode)
        if not strategy:
            raise ValueError(f"不支持的执行模式: {self.mode}")
        
        logger.info(f"使用 {self.mode.value} 模式执行分析")
        return strategy(crews)
    
    def _run_sequential(self, crews: Dict[str, Any]) -> Dict[str, Any]:
        """顺序执行（原始方法）"""
        # 这里是原始的顺序执行代码
        pass
    
    def _run_parallel(self, crews: Dict[str, Any]) -> Dict[str, Any]:
        """并行执行"""
        return run_analysis_parallel(crews)  # 使用方案1
    
    def _run_async(self, crews: Dict[str, Any]) -> Dict[str, Any]:
        """异步执行"""
        return asyncio.run(run_analysis_async(crews))  # 使用方案2
    
    def _run_advanced(self, crews: Dict[str, Any]) -> Dict[str, Any]:
        """高级并行执行"""
        return run_analysis_parallel_advanced(crews)  # 使用方案3

# 在main函数中使用
def main():
    # ... 前面的代码 ...
    
    # 根据配置或命令行参数选择执行模式
    execution_mode = ExecutionMode.PARALLEL  # 可以从配置文件读取
    executor = AnalysisExecutor(execution_mode)
    
    # 运行分析
    results = executor.run_analysis(crews)
    
    # ... 后面的代码 ...

```

```
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock
from typing import Dict, Any, Optional

class ParallelAnalysisManager:
    """并行分析管理器"""
    
    def __init__(self, max_workers: Optional[int] = None):
        self.max_workers = max_workers or 4
        self.results_lock = Lock()
        self.progress_lock = Lock()
        self.completed_count = 0
        self.total_count = 0
        
    def run_analysis_with_progress(self, crews: Dict[str, Any]) -> Dict[str, Any]:
        """
        带进度监控的并行分析执行
        
        Args:
            crews: 配置好的 Crew 实例字典
            
        Returns:
            各部门的分析结果
        """
        results = {}
        self.total_count = len(crews)
        self.completed_count = 0
        
        logger.info(f"开始并行运行分析流程，涉及 {self.total_count} 个 Crew")
        start_time = time.time()
        
        def run_crew_with_monitoring(crew_id: str, crew_instance: Any) -> tuple:
            """带监控的单个Crew执行"""
            crew_start_time = time.time()
            
            try:
                logger.info(f">>> [{crew_id}] 开始分析 <<<")
                result = crew_instance.kickoff()
                
                # 更新进度
                with self.progress_lock:
                    self.completed_count += 1
                    progress = (self.completed_count / self.total_count) * 100
                    elapsed = time.time() - crew_start_time
                    
                logger.info(f"[{crew_id}] 分析完成 (耗时: {elapsed:.2f}s, 总进度: {progress:.1f}%)")
                
                # 检查状态文件
                self._check_crew_state(crew_id)
                
                return crew_id, result, None, elapsed
                
            except Exception as e:
                with self.progress_lock:
                    self.completed_count += 1
                    
                elapsed = time.time() - crew_start_time
                logger.error(f"[{crew_id}] 执行失败 (耗时: {elapsed:.2f}s): {e}")
                logger.error(traceback.format_exc())
                
                return crew_id, None, f"Error during {crew_id} analysis: {e}", elapsed
        
        # 并行执行
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # 提交所有任务
            future_to_crew = {
                executor.submit(run_crew_with_monitoring, crew_id, crew_instance): crew_id
                for crew_id, crew_instance in crews.items()
            }
            
            # 收集结果
            execution_stats = {}
            for future in as_completed(future_to_crew):
                crew_id, result, error, elapsed = future.result()
                execution_stats[crew_id] = elapsed
                
                with self.results_lock:
                    if error:
                        results[crew_id] = error
                    else:
                        results[crew_id] = result
        
        total_elapsed = time.time() - start_time
        self._log_execution_summary(execution_stats, total_elapsed)
        
        return results
    
    def _check_crew_state(self, crew_id: str):
        """检查Crew状态文件"""
        q_space_file = os.path.join("src", "state", "q_space", f"{crew_id}.yaml")
        if os.path.exists(q_space_file):
            logger.debug(f"[{crew_id}] Q_space 文件已生成")
        else:
            logger.warning(f"[{crew_id}] Q_space 文件未找到")
    
    def _log_execution_summary(self, stats: Dict[str, float], total_time: float):
        """记录执行摘要"""
        logger.info("="*50)
        logger.info("并行执行摘要:")
        logger.info(f"总耗时: {total_time:.2f}s")
        logger.info(f"成功完成: {len([t for t in stats.values() if t > 0])}/{len(stats)}")
        
        if stats:
            avg_time = sum(stats.values()) / len(stats)
            max_time = max(stats.values())
            min_time = min(stats.values())
            
            logger.info(f"平均单个Crew耗时: {avg_time:.2f}s")
            logger.info(f"最长耗时: {max_time:.2f}s")
            logger.info(f"最短耗时: {min_time:.2f}s")
            logger.info(f"并行效率: {(sum(stats.values())/total_time):.1f}x")
        
        logger.info("="*50)

# 使用方式
def run_analysis_parallel_advanced(crews: Dict[str, Any]) -> Dict[str, Any]:
    """高级并行分析执行"""
    manager = ParallelAnalysisManager(max_workers=min(len(crews), 4))
    return manager.run_analysis_with_progress(crews)

```

```
import asyncio
import concurrent.futures
from typing import Dict, Any, List
import threading

def run_analysis_parallel(crews: Dict[str, Any]) -> Dict[str, Any]:
    """
    并行运行所有已初始化的 Crew 的分析流程
    
    Args:
        crews: 配置好的 Crew 实例字典 {crew_id: Crew}
        
    Returns:
        各部门的分析结果 {crew_id: result}
    """
    results = {}
    logger.info(f"开始并行运行分析流程，涉及 Crew: {list(crews.keys())}")
    
    def run_single_crew(crew_id: str, crew_instance: Any) -> tuple:
        """运行单个Crew的包装函数"""
        try:
            logger.info(f">>> 开始运行部门分析: {crew_id} <<<")
            result = crew_instance.kickoff()
            logger.info(f"部门 {crew_id} 分析完成")
            
            # 检查 Q_space 文件
            q_space_file = os.path.join("src", "state", "q_space", f"{crew_id}.yaml")
            if os.path.exists(q_space_file):
                logger.debug(f"部门 {crew_id} 的 Q_space 文件已存在")
            else:
                logger.warning(f"部门 {crew_id} 的 Q_space 文件未找到")
                
            return crew_id, result, None
            
        except Exception as e:
            logger.error(f"运行 Crew '{crew_id}' 时发生错误: {e}")
            logger.error(traceback.format_exc())
            return crew_id, None, f"Error during {crew_id} analysis: {e}"
    
    # 使用ThreadPoolExecutor进行并行执行
    with concurrent.futures.ThreadPoolExecutor(max_workers=len(crews)) as executor:
        # 提交所有任务
        future_to_crew = {
            executor.submit(run_single_crew, crew_id, crew_instance): crew_id 
            for crew_id, crew_instance in crews.items()
        }
        
        # 收集结果
        for future in concurrent.futures.as_completed(future_to_crew):
            crew_id, result, error = future.result()
            if error:
                results[crew_id] = error
            else:
                results[crew_id] = result
                logger.info(f"部门 {crew_id} 结果已收集")
    
    logger.info("所有并行 Crew 分析运行结束")
    return results
```

# 模块化的部门架构

每个部门独立封装的，易于扩展

# 标准化的开发模式

统一的四层架构，降低复杂度

# 智能任务的分解

基于tot的动态问题件哦和惹怒生成

# 专业画的角色分工

manager负责规划，执行agent的具体任务

# 配置驱动开发

通过yaml的配置定义agent的行为和能力的

# 工具上下文注入

自动处理crewid等上下文信息的

# 跨部门协作支持

通过共享wisebase实现的

组装层

agent管理层

task管理层

config配置层

依赖注入，brief注入到各个层级，crewid注入到工具层的

manager agent按照以下模版构建问题树

id,text,type,syatus,children,id,text.type.status,children,id,text,type,status,chdlren

动态问题分解

读取qspace和wisebase的状态

识别status是open的节点

判断节点是不是需要进一步的分解，

添加自节点到qspace当中，将具体节点转化成为执行的任务，
委派给合适的执行agent，更新节点的状态为in_progress重复循环


知识整合机制，执行agent完成任务，写入wisaebase，manager读取新的知识，更新qspace的节点的状态

任务格式化容错的

if inputs:

try:
description = description.format(**inputs)

except

工厂模式和包装起模式

工具包装起系统

qspacegetwrapper简单包装起

通过反射机制动态获取agent创建的方法的，

语义话的接口，方法名直接对应任务用途

参数注入，将brief作为模版变量注入

task生命周期管理：

配置加载load_yaml_config

任务请求initial_setup_task

配置查找create_task

agent绑定gettater+method call


模版处理string format

task实例化createAI task

绑定特点：延迟绑定，agent实例在task创建的时候才生成的，动态绑定的通过反射机制实现灵活绑定，类型安全，通过callable检查确保方法的存在


动态绑定：通过反射机制实现灵活绑定，通过callable检查确保方法存在

延迟绑定，agent实例在task创建的时候才生成

模版方法

配置验证，固定步骤，agent绑定，模版处理，task创建

反射机制实现task和agent的灵活绑定，支持参数话的任务描述，

配置驱动的任务管理，通过yaml配置定义任务模版，代码负责实例化

动态agent绑定；通过反射机制实现task和agent的灵活绑定

模版化的任务描述，支持参数话的任务描述，提高任务定义的灵活性

任务依赖管理：铜鼓context参数支持复杂的任务依赖个演戏

错误容错机制，分层的错误处理去报系统的健壮性

扩展性设计：为新任务，新工作流提供标准化的扩展模式

性能优化：配置缓存，延迟创建扽优化策略

这个设计将任务定义与任务执行分离，通过配置文件定义任务的静态属性（描述、输出格式、执行Agent），通过代码处理任务的动态属性（参数注入、依赖关系、实例创建）。这种设计既保持了系统的灵活性，又确保了任务管理的标准化和可维护性。


任务定义和任务执行分离，通过配置文件定义任务的静态属性，描述，输出格式，执行agent，通过代码处理任务的动态属性，参数注入，依赖关系，实例创建，

getattr

动态获取对象的属性和方法的，getattr(object,name[,default]);


配置驱动的，硬逼吗不灵活

getattr的动态方式，灵活并且扩展的

直接访问，静态编译的时候确定的，getattr动态运行时去定的

```
# hasattr + 直接访问
if hasattr(self.agents, agent_name):
    method = eval(f"self.agents.{agent_name}")  # 不安全！
    agent = method()

# getattr - 更安全
method = getattr(self.agents, agent_name, None)
if callable(method):
    agent = method()

```

```
# 字典映射方式
AGENT_MAPPING = {
    "competition_manager": lambda: self.agents.competition_manager(),
    "information_gatherer": lambda: self.agents.information_gatherer(),
    # 需要手动维护映射
}
agent = AGENT_MAPPING.get(agent_name, lambda: None)()

# getattr方式 - 自动映射
method = getattr(self.agents, agent_name, None)
agent = method() if callable(method) else None
```

配置驱动开发。

callable"检查对象是否可以调用的就是可以像函数一样使用括号调用的

callable(object)

使用getattr获取对象的属性

agent_method = getattr(self.agent,agent_name,None)

使用callablej勘查是否是可以调用的对象

if not callable(agent_method):raise ValueError(f'agent moethd'{agent''

callable确保获取的对象确实是可以调用的方法

在调用钱进行检查，避免运行时候的TypeError

提供清晰的错误信息，便于问题定位

增强系统对配置错误的容错能力

 method= getattr(obj,method_name,None)

 if not callable(method):
 raise ValueError(f"'{method_name}' is not calalble');
 
