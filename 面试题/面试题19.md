# Java并发与数据库技术核心知识点解析

## 一、ConcurrentHashMap实现原理

ConcurrentHashMap是Java中线程安全的哈希表实现，其设计目标是高并发下的高性能访问。

### JDK1.7与JDK1.8实现差异

1. **JDK1.7实现**：
   - 采用**分段锁(Segment)**机制，将整个哈希表分成16个Segment
   - 每个Segment继承自ReentrantLock，相当于一个小型的HashMap
   - 最高支持16个线程并发修改，读操作不加锁

2. **JDK1.8实现**：
   - 取消Segment分段锁，改用**Node数组+CAS+synchronized**
   - 锁粒度更细，只锁定链表或红黑树的头节点
   - 引入红黑树结构，当链表长度超过8时转换为红黑树

### 核心操作原理

- **put操作流程**：
  1. 计算key的hash值
  2. 如果表为空则初始化
  3. 如果对应桶为空，使用CAS插入
  4. 如果发现正在扩容，则帮助扩容
  5. 如果有冲突，则使用synchronized锁住头节点处理

- **size计算**：
  - JDK1.7需要锁定所有Segment后统计
  - JDK1.8使用CounterCell数组和baseCount来统计，避免全局锁定

## 二、synchronized锁升级机制

Java中的synchronized锁会经历从无锁到重量级锁的逐步升级过程，这种优化称为锁膨胀。

### 锁升级的四个阶段

1. **无锁状态**：
   - 对象刚创建时的初始状态
   - 无任何同步开销

2. **偏向锁**：
   - 第一个线程访问同步块时启用
   - 在对象头记录线程ID，后续同一线程进入无需同步操作
   - 适用于单线程重复访问场景

3. **轻量级锁**：
   - 当有第二个线程尝试获取锁时升级
   - 线程通过自旋(CAS)尝试获取锁
   - 适用于多线程交替执行场景

4. **重量级锁**：
   - 当自旋超过阈值(默认10次)或多个线程持续竞争时升级
   - 依赖操作系统互斥量实现，线程会被挂起
   - 适用于高并发竞争场景

### 锁升级触发条件

| 升级路径 | 触发条件 |
|---------|---------|
| 无锁→偏向锁 | 第一个线程访问同步块 |
| 偏向锁→轻量级锁 | 第二个线程尝试获取锁 |
| 轻量级锁→重量级锁 | 自旋超过阈值或多个线程持续竞争 |

### 锁升级性能影响

- **偏向锁**：加解锁几乎无开销(仅1次CAS)
- **轻量级锁**：自旋消耗CPU但避免线程阻塞
- **重量级锁**：线程阻塞/唤醒开销大(微秒级)

## 三、Redis脑裂问题及解决方案

Redis脑裂(Split-Brain)是指集群因网络分区导致不同节点间无法通信，各自形成独立子集群并继续处理请求，最终引发数据不一致的严重故障。

### 脑裂发生原理

1. 主节点A与哨兵、从节点间网络中断
2. 哨兵判定A下线，选举Slave B为新主
3. 客户端分区1继续写入原主A
4. 客户端分区2向新主B写入数据
5. 结果：主库A与B各自独立写入，数据分叉

### 脑裂的灾难性后果

1. **数据丢失**：原主A恢复后被设为从库，其差异数据被清空
2. **脏读**：客户端交替读到新旧主数据
3. **服务不可用**：客户端持续写入旧主导致请求积压

### 防治脑裂的核心策略

1. **参数优化配置**：
   ```shell
   # 限制主节点最少从节点数
   min-slaves-to-write 2
   # 主节点写入需至少同步到N个从库
   min-slaves-max-lag 10
   ```
   当从库数量不足或延迟过高时，主节点停止接受写请求

2. **哨兵部署规范**：
   - 奇数节点：哨兵集群部署≥3节点且数量为奇数
   - 跨物理隔离：哨兵分散在不同机架/AZ
   - 资源隔离：哨兵独立部署，不与Redis进程混部

3. **网络可靠性增强**：
   - 使用Keepalived实现VIP浮动
   - 优化网络配置减少分区风险

## 四、RabbitMQ与Kafka的核心区别

RabbitMQ和Kafka是两种常见的消息队列系统，但它们的设计目标、使用场景和底层原理有显著的区别。

### 核心区别对比

| 特性 | RabbitMQ | Kafka |
|------|---------|-------|
| 设计目标 | 解耦、异步处理和负载均衡 | 高吞吐量的日志收集和流式数据处理 |
| 消息模型 | 基于AMQP协议，多种消息模型 | 基于日志的分布式流处理模型 |
| 吞吐量 | 较低，适合中小规模 | 极高，适合大规模数据 |
| 延迟 | 较低，适合实时性要求高 | 较高，但可优化 |
| 消费模式 | 消息被消费后移除(推模式) | 消息持久化，可多次读取(拉模式) |
| 扩展性 | 有限，适合中小型集群 | 高度可扩展，支持分布式部署 |

### 使用场景

**RabbitMQ适用场景**：
- 任务队列(如发送邮件、生成报表)
- 应用解耦(微服务间通信)
- 流量削峰(缓冲高并发请求)
- 广播通知(实时推送)

**Kafka适用场景**：
- 日志收集(如ELK系统)
- 流式处理(用户行为分析)
- 事件溯源(状态变化记录)
- 大数据管道(连接Hadoop/Spark)

### 底层原理差异

**RabbitMQ**：
- 基于AMQP协议实现消息传递
- 核心组件：生产者、消费者、队列、交换器和绑定
- 支持多种交换器类型(Direct、Fanout等)

**Kafka**：
- 将消息存储为不可变的日志文件
- 每个主题(Topic)分为多个分区(Partition)
- 消费者通过偏移量(Offset)读取消息
- 使用批量读写和零拷贝技术提升性能

## 五、Oracle与MySQL的区别

Oracle和MySQL作为两大主流关系型数据库，在功能、性能、适用场景等方面存在显著差异。

### 六大核心区别

1. **事务与并发控制**：
   - MySQL默认自动提交，Oracle默认手动提交
   - Oracle的MVCC机制在高并发下更优

2. **存储引擎与架构**：
   - MySQL支持多引擎(InnoDB、MyISAM等)
   - Oracle单一集成引擎，支持分布式集群(RAC)

3. **性能与优化**：
   - Oracle优化器更智能，支持并行查询
   - MySQL优化器相对简单

4. **数据安全与高可用**：
   - Oracle支持热备份和细粒度恢复
   - MySQL逻辑备份需锁表

5. **语法差异**：
   - 分页：MySQL用`LIMIT`，Oracle用`ROWNUM`
   - 自增主键：MySQL支持`AUTO_INCREMENT`，Oracle用序列

6. **成本与适用场景**：
   - MySQL开源免费，适合中小型应用
   - Oracle商业授权，适合大型企业应用

### 选择建议

**选择Oracle的场景**：
- 企业级高并发、复杂查询需求
- 严格安全合规要求
- 需要长期稳定支持

**选择MySQL的场景**：
- 成本敏感、快速部署项目
- 轻量化Web应用
- 结合分库分表技术扩展


# Java与Spring技术深度解析

## 一、Java集合与并发安全

### Java集合体系

**主要集合分类**：
1. **Collection**：
   - List：有序可重复（ArrayList、LinkedList、Vector）
   - Set：无序不重复（HashSet、TreeSet、LinkedHashSet）
   - Queue：队列（LinkedList、PriorityQueue）

2. **Map**：
   - HashMap、TreeMap、LinkedHashMap、Hashtable

### List的线程安全实现

1. **Vector**：JDK1.0提供的线程安全List，所有方法用synchronized修饰
2. **Collections.synchronizedList**：包装器模式实现的线程安全List
3. **CopyOnWriteArrayList**：写时复制技术实现的线程安全List（适合读多写少场景）

### ConcurrentHashMap并发安全实现

1. **JDK1.7**：
   - 分段锁（Segment）机制，默认16个段
   - 每个段相当于一个Hashtable
   - 并发度取决于Segment数量

2. **JDK1.8**：
   - 取消分段锁，改用Node数组+CAS+synchronized
   - 锁粒度细化到链表/红黑树的头节点
   - 使用volatile保证可见性
   - 引入红黑树优化哈希冲突性能

## 二、锁机制对比

### synchronized vs ReentrantLock

| 特性 | synchronized | ReentrantLock |
|------|-------------|--------------|
| 实现 | JVM原生支持 | JDK实现 |
| 锁获取 | 自动获取释放 | 必须手动释放 |
| 公平性 | 非公平 | 可配置公平/非公平 |
| 中断 | 不支持 | 支持lockInterruptibly() |
| 条件 | 单一等待队列 | 可创建多个Condition |
| 性能 | 优化后差距不大 | 更灵活 |
| 锁绑定 | 与对象绑定 | 与线程绑定 |

**ReentrantLock优势场景**：
- 需要尝试获取锁（tryLock）
- 需要公平锁
- 需要多条件变量
- 需要可中断的锁获取

## 三、Spring AOP实现原理

### AOP实现方式

1. **JDK动态代理**：
   - 基于接口实现
   - 运行时生成代理类
   - 核心类：Proxy、InvocationHandler

2. **CGLIB字节码增强**：
   - 基于子类继承
   - 不需要接口
   - 生成目标类的子类

### AOP执行流程

1. **代理创建**：
   - 根据配置决定使用JDK或CGLIB
   - 生成代理对象

2. **拦截链执行**：
   - 方法调用时触发拦截器链
   - 按顺序执行前置通知→目标方法→后置通知

3. **通知类型**：
   - @Before
   - @After
   - @AfterReturning
   - @AfterThrowing
   - @Around

## 四、Spring Bean生命周期

### 完整生命周期

1. **实例化**：
   - 通过构造器或工厂方法创建实例

2. **属性赋值**：
   - 依赖注入（@Autowired等）

3. **初始化**：
   - 调用Aware接口方法（BeanNameAware等）
   - BeanPostProcessor前置处理
   - InitializingBean.afterPropertiesSet()
   - 自定义init-method
   - BeanPostProcessor后置处理

4. **使用期**：
   - 应用程序使用Bean

5. **销毁期**：
   - DisposableBean.destroy()
   - 自定义destroy-method

### 关键扩展点

```java
public interface BeanPostProcessor {
    // 初始化前回调
    Object postProcessBeforeInitialization(Object bean, String beanName);
    
    // 初始化后回调
    Object postProcessAfterInitialization(Object bean, String beanName);
}
```

## 五、Spring Boot事务失效场景

### 常见失效原因

1. **方法非public**：
   - Spring事务代理要求public方法

2. **自调用问题**：
   - 同一类中方法调用不走代理

3. **异常类型不匹配**：
   - 默认只回滚RuntimeException
   - 检查异常需要显式配置

4. **数据库引擎不支持**：
   - MyISAM引擎不支持事务

5. **传播行为配置不当**：
   - PROPAGATION_SUPPORTS在不存事务时不会新建事务

6. **多数据源未指定**：
   - 需要明确指定事务管理器

### 解决方案

```java
// 正确的事务注解使用示例
@Transactional(
    propagation = Propagation.REQUIRED,
    isolation = Isolation.DEFAULT,
    rollbackFor = Exception.class
)
public void businessMethod() {
    // 业务逻辑
}
```

## 六、JVM内存与GC

### JVM内存模型

1. **程序计数器**：线程私有，记录执行位置
2. **虚拟机栈**：线程私有，存储栈帧
3. **本地方法栈**：Native方法调用
4. **堆**：对象实例存储区域（GC主要区域）
5. **方法区**：类信息、常量、静态变量（JDK8后为元空间）

### 垃圾回收策略

1. **分代收集理论**：
   - 新生代（Eden+Survivor）
   - 老年代
   - 永久代/元空间

2. **常见GC算法**：
   - 标记-清除
   - 标记-整理
   - 复制算法

### CMS vs G1

| 特性 | CMS | G1 |
|------|-----|----|
| 目标 | 低延迟 | 平衡吞吐与延迟 |
| 区域 | 传统分代 | 分区(Region) |
| 算法 | 标记-清除 | 标记-整理+复制 |
| 停顿 | 并发收集 | 可预测停顿 |
| 适用 | 中小堆 | 大堆(>4G) |
| 版本 | JDK9标记废弃 | JDK9+默认 |

## 七、OOM排查方法

### 排查步骤

1. **获取堆转储**：
   ```bash
   # 自动生成dump文件
   -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/path/to/dump.hprof
   ```

2. **分析工具**：
   - VisualVM
   - Eclipse MAT
   - JProfiler

3. **常见OOM类型**：
   - Java heap space（堆内存不足）
   - GC overhead limit exceeded（GC效率低下）
   - PermGen space/Metaspace（元数据区溢出）
   - Unable to create new native thread（线程数超限）

### 典型解决策略

1. **堆内存不足**：
   - 增大-Xmx
   - 检查内存泄漏
   - 优化对象创建

2. **元空间溢出**：
   - 增大-XX:MaxMetaspaceSize
   - 检查动态类生成

3. **线程数超限**：
   - 减少线程数
   - 优化线程池配置

## 八、MySQL隔离级别

### 四种隔离级别

| 隔离级别 | 脏读 | 不可重复读 | 幻读 | 实现机制 |
|---------|------|-----------|------|---------|
| 读未提交(READ UNCOMMITTED) | 可能 | 可能 | 可能 | 无锁 |
| 读已提交(READ COMMITTED) | 不可能 | 可能 | 可能 | 快照读(MVCC) |
| 可重复读(REPEATABLE READ) | 不可能 | 不可能 | 可能(InnoDB不可能) | MVCC+间隙锁 |
| 串行化(SERIALIZABLE) | 不可能 | 不可能 | 不可能 | 全表锁 |

### InnoDB的RR级别实现

1. **MVCC机制**：
   - 多版本并发控制
   - 通过ReadView实现一致性读

2. **间隙锁(Gap Lock)**：
   - 防止幻读
   - 锁定索引记录间的间隙

## 九、MySQL索引失效场景

### 常见失效情况

1. **违反最左前缀原则**：
   - 复合索引(a,b,c)，查询条件无a

2. **隐式类型转换**：
   - 字段varchar，条件用数字比较

3. **使用函数或运算**：
   ```sql
   WHERE YEAR(create_time) = 2023  -- 索引失效
   ```

4. **使用不等于(!=或<>)**
5. **LIKE以通配符开头**：
   ```sql
   WHERE name LIKE '%张'  -- 索引失效
   ```

6. **OR条件未全索引**：
   - OR的一边无索引则全失效

7. **索引列参与计算**：
   ```sql
   WHERE age + 1 > 20  -- 索引失效
   ```

### 优化建议

1. 使用EXPLAIN分析执行计划
2. 避免SELECT *
3. 合理设计复合索引顺序
4. 考虑使用覆盖索引

## 十、表结构优化场景

### 典型优化场景

1. **大表拆分**：
   - 垂直拆分（按列）
   - 水平拆分（按行）

2. **字段优化**：
   - 使用合适的数据类型
   - 避免NULL值（设置默认值）
   - 大文本分离到单独表

3. **索引优化**：
   - 合理添加索引
   - 避免冗余索引
   - 使用前缀索引

4. **范式与反范式平衡**：
   - 适当冗余减少JOIN
   - 保持数据一致性

5. **分区表**：
   - 按范围/列表/哈希分区
   - 提高大表查询效率

## 十一、Elasticsearch写入策略

### 核心写入流程

1. **客户端请求**：
   - 发送到协调节点

2. **路由分发**：
   - 根据文档ID哈希确定主分片
   - 并行转发到副本分片

3. **写入阶段**：
   - 先写入内存缓冲区
   - 同时写入事务日志(translog)

4. **刷新(Refresh)**：
   - 默认1秒将内存数据生成新段(segment)
   - 使文档可被搜索

5. **刷盘(Flush)**：
   - 定期将内存数据和translog持久化

### 写入优化策略

1. **批量写入(Bulk API)**：
   - 减少网络开销
   - 控制每批5-15MB

2. **调整刷新间隔**：
   ```json
   PUT /index/_settings
   {
     "index.refresh_interval": "30s"
   }
   ```

3. **禁用副本提高写入**：
   - 写入时设置index.number_of_replicas: 0
   - 写入完成后再恢复

4. **使用自动生成ID**：
   - 避免ID唯一性检查开销

5. **合理分片数**：
   - 建议每个分片30-50GB
   - 分片数=节点数×CPU核数

### 一致性保证

1. **参数控制**：
   ```json
   {
     "consistency": "quorum",
     "timeout": "1m"
   }
   ```

2. **写入确认级别**：
   - one：主分片成功
   - quorum：多数分片成功(default)
   - all：全部分片成功
